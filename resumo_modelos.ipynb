{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc3sAvCGm8H8"
      },
      "source": [
        " ## Descrição dos resultados dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algumas observações gerais sobre a preparação dos dados:\n",
        "\n",
        "- Para cada modelo foram escolhidas 5 variáveis diferentes;\n",
        "- Os dados nulos foram substituídos por zero;\n",
        "- Para a separação da base entre treino e teste utilizados test_size=0.2 e random_state=4;\n",
        "- Por conta do desbalanceamento dos dados, utilizamos a métrica ROC-AUC para comparação da performance entre os modelos e não a acurácia, mas observamos também o Recall pois pensamos em priorizar resultados que reduzem os falsos negativos, assumindo que os mesmos podem implicar em riscos maiores para o negócio caso deixemos passar clientes ruins.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHwkohCOnRLB"
      },
      "source": [
        "**Árvore de Decisão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6bFakZknX3l"
      },
      "source": [
        "- **ROC = 0.6222**\n",
        "- Por conta do desbalanceamento entre as classes, fizemos uso do parâmetro *class_weight* do modelo para contrabalancear;\n",
        "- Como nesse primeiro momento o objetivo não é melhoria de performance, podamos a árvore em uma profundidade máxima = 4 para poder facilitar a visualização da mesma;\n",
        "- Recall de apenas 0.52 para a classe positiva, indicando um alto risco de classificação de falsos negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f5V-EBTnWtE"
      },
      "source": [
        "**Random Forest**\n",
        "\n",
        "- **ROC = 0.9267**\n",
        "- Utilizamos o método de oversampling SMOTE para ajustar o balanceamento dos dados;\n",
        "- Obteve a melhor ROC entre os modelos testados;\n",
        "- Recall de 0.82 para a classe positiva, indicando uma boa performance média com a classificação de menos falsos negativos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMV7uWOpnt68"
      },
      "source": [
        "**KNN**\n",
        "\n",
        "- **ROC = 0.8865**\n",
        "- Utilizamos o método de oversampling SMOTE para ajustar o balanceamento dos dados;\n",
        "- Quando K=5 observamos no gráfico que a taxa de erro é menor que 10%, por isso selecionamos esses valores para K;\n",
        "- Já no segundo gráfico se aumentarmos o número K é possível perceber que o nível de acurácia do modelo tende a cair;\n",
        "- A métrica ROC foi de 0.88. Para a classe 0 o modelo obteve precisão de 0.90, já para classe 1 0.87;\n",
        "- Recall de 0.90 para a classe positiva, indicando uma ótima performance média com a classificação de menos falsos negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NajWEba7nw9K"
      },
      "source": [
        "**Naive Bayes**\n",
        "\n",
        "- **ROC = 0.5**\n",
        "- Não usamos nenhum método de balanceamento entre as classes; \n",
        "- Acreditamos que a baixa performance da métrica ROC foi muito impactada pelo desbalanceamento entre as classes. Isso acontece pois se existem menos registros proporcionalmente entre as classes, a probabilidade de ocorrência do evento com menos registro é menor, induzindo o modelo ao erro;\n",
        "- Recall igual a zero para a classe positiva, indicando que o modelo possui problemas a serem resolvidos pois tem dificuldades em generalizar a classe com menos amostras, conforme descrito no bullet acima.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusão\n",
        "\n",
        "- O melhor modelo foi o RandomForest;\n",
        "- Acreditamos que quando aprendermos novos métodos para tratar balanceamento de classes a performance dos outros modelos pode melhorar, em especial para o Naive Bayes;\n",
        "- A árvore de decisão, mesmo tentando tratar o desbalanceamento com o parâmetro *class_weight* ficou bem abaixo do KNN e do Random Forest observando as métricas ROC e Recall . Seria interessante testar ela novamente tratando o desbalanceamento de outra forma;\n",
        "- Cada modelo fez uso de um conjunto de variáveis diferentes. Isso pode trazer grandes impactos na comparação simples da performance entre os modelos. Quando aprendermos novos métodos avançados de seleção de variáveis podemos ter mais certeza de qual modelo funciona melhor para esse conjunto de dados.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "dbe8995998cd657a3996bebceea8c9fbddd3319e7ed17a149bf729e2bf8225ca"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
